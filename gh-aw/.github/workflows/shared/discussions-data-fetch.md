---
tools:
  cache-memory:
    key: discussions-data
  bash:
    - "gh api *"
    - "jq *"
    - "/tmp/gh-aw/jqschema.sh"
    - "mkdir *"
    - "date *"
    - "cp *"
    - "ln *"

steps:
  - name: Fetch discussions data
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      REPO_OWNER: ${{ github.repository_owner }}
      REPO_NAME: ${{ github.event.repository.name }}
    run: |
      # Create output directories
      mkdir -p /tmp/gh-aw/discussions-data
      mkdir -p /tmp/gh-aw/cache-memory
      
      # Get today's date for cache identification
      TODAY=$(date '+%Y-%m-%d')
      CACHE_DIR="/tmp/gh-aw/cache-memory"
      
      # Check if cached data exists from today
      if [ -f "$CACHE_DIR/discussions-${TODAY}.json" ] && [ -s "$CACHE_DIR/discussions-${TODAY}.json" ]; then
        echo "✓ Found cached discussions data from ${TODAY}"
        cp "$CACHE_DIR/discussions-${TODAY}.json" /tmp/gh-aw/discussions-data/discussions.json
        
        # Regenerate schema if missing
        if [ ! -f "$CACHE_DIR/discussions-${TODAY}-schema.json" ]; then
          /tmp/gh-aw/jqschema.sh < /tmp/gh-aw/discussions-data/discussions.json > "$CACHE_DIR/discussions-${TODAY}-schema.json"
        fi
        cp "$CACHE_DIR/discussions-${TODAY}-schema.json" /tmp/gh-aw/discussions-data/discussions-schema.json
        
        echo "Using cached data from ${TODAY}"
        echo "Total discussions in cache: $(jq 'length' /tmp/gh-aw/discussions-data/discussions.json)"
      else
        echo "⬇ Downloading fresh discussions data..."
        
        # Fetch all OPEN discussions using GraphQL with pagination
        DISCUSSIONS_FILE="/tmp/gh-aw/discussions-data/discussions.json"
        echo '[]' > "$DISCUSSIONS_FILE"
        
        CURSOR=""
        HAS_NEXT_PAGE=true
        PAGE_COUNT=0
        
        while [ "$HAS_NEXT_PAGE" = "true" ]; do
          if [ -z "$CURSOR" ]; then
            CURSOR_ARG=""
          else
            CURSOR_ARG=", after: \"$CURSOR\""
          fi
          
          RESULT=$(gh api graphql -f query="
            query {
              repository(owner: \"$REPO_OWNER\", name: \"$REPO_NAME\") {
                discussions(first: 100, states: [OPEN]${CURSOR_ARG}) {
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                  nodes {
                    number
                    title
                    body
                    createdAt
                    updatedAt
                    url
                    category {
                      name
                      slug
                    }
                    author {
                      login
                    }
                    labels(first: 10) {
                      nodes {
                        name
                      }
                    }
                  }
                }
              }
            }
          ")
          
          # Extract discussions and normalize structure
          echo "$RESULT" | jq -r '
            .data.repository.discussions.nodes 
            | map({
                number, 
                title,
                body,
                createdAt, 
                updatedAt,
                url,
                category: .category.name,
                categorySlug: .category.slug,
                author: (if .author then .author.login else "unknown" end),
                labels: [.labels.nodes[].name],
                isAgenticWorkflow: (if .body then (.body | test("^> AI generated by"; "m")) else false end)
              })
          ' | jq -s 'add' > /tmp/gh-aw/temp_discussions.json
          
          # Merge with existing discussions
          jq -s 'add | unique_by(.number)' "$DISCUSSIONS_FILE" /tmp/gh-aw/temp_discussions.json > /tmp/gh-aw/merged.json
          mv /tmp/gh-aw/merged.json "$DISCUSSIONS_FILE"
          rm -f /tmp/gh-aw/temp_discussions.json
          
          # Check if there are more pages
          HAS_NEXT_PAGE=$(echo "$RESULT" | jq -r '.data.repository.discussions.pageInfo.hasNextPage')
          CURSOR=$(echo "$RESULT" | jq -r '.data.repository.discussions.pageInfo.endCursor')
          
          # Check if we've reached the requested count
          CURRENT_COUNT=$(jq 'length' "$DISCUSSIONS_FILE")
          MAX_COUNT="${GH_AW_DISCUSSIONS_COUNT:-100}"
          if [ "$CURRENT_COUNT" -ge "$MAX_COUNT" ]; then
            echo "Reached requested discussion count ($MAX_COUNT)"
            # Trim to exact count if we have more
            jq --argjson max "$MAX_COUNT" '.[:$max]' "$DISCUSSIONS_FILE" > /tmp/gh-aw/trimmed.json
            mv /tmp/gh-aw/trimmed.json "$DISCUSSIONS_FILE"
            break
          fi
          
          # Safety check - break after 10 pages (1000 discussions max regardless of count)
          PAGE_COUNT=$((PAGE_COUNT + 1))
          if [ $PAGE_COUNT -ge 10 ]; then
            echo "Reached pagination limit (10 pages)"
            break
          fi
        done
        
        # Generate schema for reference
        /tmp/gh-aw/jqschema.sh < /tmp/gh-aw/discussions-data/discussions.json > /tmp/gh-aw/discussions-data/discussions-schema.json

        # Store in cache with today's date
        cp /tmp/gh-aw/discussions-data/discussions.json "$CACHE_DIR/discussions-${TODAY}.json"
        cp /tmp/gh-aw/discussions-data/discussions-schema.json "$CACHE_DIR/discussions-${TODAY}-schema.json"

        echo "✓ Discussions data saved to cache: discussions-${TODAY}.json"
        echo "Total discussions found: $(jq 'length' /tmp/gh-aw/discussions-data/discussions.json)"
      fi
      
      # Always ensure data is available at expected locations for backward compatibility
      echo "Discussions data available at: /tmp/gh-aw/discussions-data/discussions.json"
      echo "Schema available at: /tmp/gh-aw/discussions-data/discussions-schema.json"
---

<!--
## Discussions Data Fetch

This shared component fetches open discussions from the repository, with intelligent caching to avoid redundant API calls.

### What It Does

1. Creates output directories at `/tmp/gh-aw/discussions-data/` and `/tmp/gh-aw/cache-memory/`
2. Checks for cached discussions data from today's date in cache-memory
3. If cache exists (from earlier workflow runs today):
   - Uses cached data instead of making API calls
   - Copies data from cache to working directory
4. If cache doesn't exist:
   - Fetches open discussions using GitHub GraphQL API with pagination
   - Saves data to cache with date-based filename (e.g., `discussions-2024-11-18.json`)
   - Copies data to working directory for use
5. Generates a schema of the data structure

### Caching Strategy

- **Cache Key**: `discussions-data` for workflow-level sharing
- **Cache Files**: Stored with today's date in the filename (e.g., `discussions-2024-11-18.json`)
- **Cache Location**: `/tmp/gh-aw/cache-memory/`
- **Cache Benefits**: 
  - Multiple workflows running on the same day share the same discussions data
  - Reduces GitHub API rate limit usage
  - Faster workflow execution after first fetch of the day

### Output Files

- **`/tmp/gh-aw/discussions-data/discussions.json`**: Full discussions data including number, title, author, timestamps, category, labels, etc.
- **`/tmp/gh-aw/discussions-data/discussions-schema.json`**: JSON schema showing the structure of the discussions data

### Requirements

- Requires `jqschema.md` to be imported for schema generation
- Uses GitHub GraphQL API to fetch open discussions
- Cache-memory tool is automatically configured for data persistence
-->

## Discussions Data

Pre-fetched discussions data is available at `/tmp/gh-aw/discussions-data/discussions.json` containing open discussions.

### Schema

The discussions data structure is:

```json
[
  {
    "number": "number",
    "title": "string",
    "body": "string",
    "createdAt": "string (ISO 8601 timestamp)",
    "updatedAt": "string (ISO 8601 timestamp)",
    "url": "string",
    "category": "string",
    "categorySlug": "string",
    "author": "string",
    "labels": ["string"],
    "isAgenticWorkflow": "boolean (true if body contains '> AI generated by')"
  }
]
```

### Usage Examples

```bash
# Get total number of discussions
jq 'length' /tmp/gh-aw/discussions-data/discussions.json

# Get discussions by a specific author
jq '[.[] | select(.author == "github-actions[bot]")]' /tmp/gh-aw/discussions-data/discussions.json

# Get discussions older than 7 days (cross-platform: GNU date first, BSD fallback)
DATE_7_DAYS_AGO=$(date -d '7 days ago' '+%Y-%m-%dT%H:%M:%SZ' 2>/dev/null || date -v-7d '+%Y-%m-%dT%H:%M:%SZ')
jq --arg date "$DATE_7_DAYS_AGO" '[.[] | select(.createdAt < $date)]' /tmp/gh-aw/discussions-data/discussions.json

# Get discussion numbers
jq '[.[].number]' /tmp/gh-aw/discussions-data/discussions.json

# Get discussions by category
jq '[.[] | select(.category == "General")]' /tmp/gh-aw/discussions-data/discussions.json

# Get discussions with a specific title pattern (e.g., daily reports)
jq '[.[] | select(.title | test("Daily Report|Weekly Report"; "i"))]' /tmp/gh-aw/discussions-data/discussions.json
```
